{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68b56cfe-9422-43da-9d5f-b037ab6a188c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T20:01:59.542236Z",
     "iopub.status.busy": "2023-05-22T20:01:59.541597Z",
     "iopub.status.idle": "2023-05-22T20:01:59.547374Z",
     "shell.execute_reply": "2023-05-22T20:01:59.546448Z",
     "shell.execute_reply.started": "2023-05-22T20:01:59.542192Z"
    }
   },
   "outputs": [],
   "source": [
    "#!unzip /datasets/dfu/dfuSegmentation.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18628524-840d-458e-a04b-0f27f1ee6f50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T08:53:05.855365Z",
     "iopub.status.busy": "2023-05-26T08:53:05.855044Z",
     "iopub.status.idle": "2023-05-26T08:53:11.662661Z",
     "shell.execute_reply": "2023-05-26T08:53:11.661528Z",
     "shell.execute_reply.started": "2023-05-26T08:53:05.855337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from albumentations) (5.4.1)\n",
      "Collecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from albumentations) (1.9.2)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.9/dist-packages (from albumentations) (0.19.3)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.9/dist-packages (from albumentations) (1.23.4)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (23.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (3.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (2.25.0)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (9.2.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.1.23.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n",
      "Installing collected packages: opencv-python-headless, qudida, albumentations\n",
      "Successfully installed albumentations-1.3.0 opencv-python-headless-4.7.0.72 qudida-0.0.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be87442e-0953-445c-992c-de907a6f8211",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T08:53:11.665337Z",
     "iopub.status.busy": "2023-05-26T08:53:11.664963Z",
     "iopub.status.idle": "2023-05-26T08:53:11.671472Z",
     "shell.execute_reply": "2023-05-26T08:53:11.670614Z",
     "shell.execute_reply.started": "2023-05-26T08:53:11.665301Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def ReadFiles(directory):\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        files_ = sorted([f'{directory}/{file}' for file in files], key=str)\n",
    "        return files_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93be51ea-08fa-434f-8103-053ffdddbe05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T08:53:11.673200Z",
     "iopub.status.busy": "2023-05-26T08:53:11.672855Z",
     "iopub.status.idle": "2023-05-26T08:53:13.128173Z",
     "shell.execute_reply": "2023-05-26T08:53:13.127015Z",
     "shell.execute_reply.started": "2023-05-26T08:53:11.673167Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import albumentations as A\n",
    "\n",
    "class DFUDataset(Dataset):\n",
    "    \"\"\" Custom dataset initiation for diabetic foot ulcer segmentation dataset. \"\"\" \n",
    "\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.transform = transform\n",
    "        self.images, self.masks = image_dir, mask_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, mask = cv2.imread(self.images[idx]), cv2.imread(self.masks[idx], cv2.IMREAD_GRAYSCALE)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=image, mask=mask)\n",
    "            image, mask = transformed['image'].to(torch.float32) / 255, transformed['mask'].to(torch.float32) / 255\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4a82a27-65a3-49bd-87f2-aee49aa2315d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T08:53:13.130372Z",
     "iopub.status.busy": "2023-05-26T08:53:13.129736Z",
     "iopub.status.idle": "2023-05-26T08:53:13.397553Z",
     "shell.execute_reply": "2023-05-26T08:53:13.396883Z",
     "shell.execute_reply.started": "2023-05-26T08:53:13.130347Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "#PyTorch\n",
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1e-5):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = torch.sigmoid(inputs)\n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                         \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice\n",
    "    \n",
    "def BCEWithLogitsLoss():\n",
    "    return torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def IOU(outputs, labels, device):\n",
    "    output = torch.sigmoid(outputs)\n",
    "    output = torch.where(output < 0.5, torch.tensor(0.0).to(device), torch.tensor(1.0).to(device)).flatten()\n",
    "    label = labels.flatten()\n",
    "    \n",
    "    intersection = torch.logical_and(label, output)\n",
    "    union = torch.logical_or(label, output)\n",
    "    \n",
    "    return torch.sum(intersection) / torch.sum(union)\n",
    "\n",
    "def SGD(model, lr=0.1):\n",
    "    return torch.optim.SGD(params=model.parameters(), lr=lr)\n",
    "\n",
    "def Adam(model, lr=0.1):\n",
    "    return torch.optim.Adam(params = model.parameters(), lr=lr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c513a45c-cfe0-4923-857e-897d19cc94db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T08:53:13.399172Z",
     "iopub.status.busy": "2023-05-26T08:53:13.398655Z",
     "iopub.status.idle": "2023-05-26T08:53:13.425659Z",
     "shell.execute_reply": "2023-05-26T08:53:13.424573Z",
     "shell.execute_reply.started": "2023-05-26T08:53:13.399147Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import time\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def Train(model, epochs, optimizer, scheduler, loss_fn, train_iter, val_iter, device, early_stopping, DeepLab=False):\n",
    "    # Create dictionary to store history\n",
    "    Loss = {\"val_iou\":[]}\n",
    "\n",
    "    with open('./models/readme.txt', 'w') as f:\n",
    "        f.write('Model: {} \\n Max Epochs: {} \\n Optimizer: {} \\n Scheduler: {} \\n Loss Function: {} \\n Device: {} \\n Early Stopping: {}'.format(model, epochs, optimizer, scheduler, loss_fn, device, early_stopping))\n",
    "\n",
    "    with open('./models/log.csv', 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"epoch\",\"train_loss\",\"train_iou\",\"val_loss\",\"val_iou\"])\n",
    "    \n",
    "    # Set patience to zero.\n",
    "    patience = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Set model in training mode\n",
    "        model.train()\n",
    "\n",
    "        # Initialise cumulative loss\n",
    "        train_loss, train_iou, val_loss, val_iou = 0, 0, 0, 0\n",
    "        \n",
    "        # Print LR if it has decreased.\n",
    "        if epoch != 0:\n",
    "            if optimizer.param_groups[0]['lr'] < LR:\n",
    "                print('Learning rate decreased to ', optimizer.param_groups[0]['lr'])\n",
    "        else:\n",
    "            print('Initial learning rate set to ', optimizer.param_groups[0]['lr'])\n",
    "        LR = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Loop over the training set\n",
    "        for i, data in enumerate(tqdm(train_iter)):\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Zero previous gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "            # Generate predictions and loss with current model parameters\n",
    "            if DeepLab == True:\n",
    "                outputs = model(inputs)[\"out\"]\n",
    "            else:\n",
    "                outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Initiate backpropagation to adjust loss weights\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update total training loss\n",
    "            train_loss += loss\n",
    "            train_iou += IOU(outputs, labels, device)\n",
    "        train_steps = i+1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Set the model to evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # Loop over the validation set\n",
    "            for i, data in enumerate(tqdm(val_iter)):\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "                # Calculate validation loss\n",
    "                if DeepLab == True:\n",
    "                    outputs = model(inputs)[\"out\"]\n",
    "                else:\n",
    "                    outputs = model(inputs)\n",
    "                val_loss += loss_fn(outputs, labels)\n",
    "                val_iou += IOU(outputs, labels, device)\n",
    "            val_steps = i+1\n",
    "        \n",
    "        # Calculate the average training and validation loss\n",
    "        avg_train_loss = float(train_loss / train_steps)\n",
    "        avg_train_iou = float(train_iou / train_steps)\n",
    "        avg_val_loss = float(val_loss / val_steps)\n",
    "        avg_val_iou = float(val_iou / val_steps)\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step(avg_val_loss)\n",
    "\n",
    "        # Save the best model if appropriate, else continue.\n",
    "        if epoch == 0:\n",
    "            torch.save(model.state_dict(), \"./models/model.pth\")\n",
    "            print(\"Saved best model!\")\n",
    "        elif avg_val_iou > np.max(Loss[\"val_iou\"]):\n",
    "            torch.save(model.state_dict(), './models/model.pth')\n",
    "            print(\"Saved best model!\")\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "\n",
    "        # Update train and val loss history\n",
    "        Loss[\"val_iou\"].append(avg_val_iou)\n",
    "\n",
    "        with open('./models/log.csv', 'a') as csv_file:\n",
    "            dict_object = csv.DictWriter(csv_file, fieldnames=[\"epoch\",\"train_loss\",\"train_iou\",\"val_loss\",\"val_iou\"])\n",
    "            dict_object.writerow({\"epoch\":epoch,\"train_loss\":avg_train_loss,\"train_iou\":avg_train_iou,\"val_loss\":avg_val_loss,\"val_iou\":avg_val_iou})\n",
    "\n",
    "        print(\"Epoch {}, Train Loss {:3f}, Train IOU {:3f}, Val Loss {:3f}, Val IOU {:3f}\".format(\n",
    "            epoch, avg_train_loss, avg_train_iou, avg_val_loss, avg_val_iou))\n",
    "        \n",
    "        if patience > early_stopping:\n",
    "            print(\"Early stopping triggered, best val IOU: {}\".format(np.max(Loss[\"val_iou\"])))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3a880f-455f-4ce0-8b0a-a7bbdd654a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T08:53:13.427859Z",
     "iopub.status.busy": "2023-05-26T08:53:13.426871Z",
     "iopub.status.idle": "2023-05-26T08:53:13.480715Z",
     "shell.execute_reply": "2023-05-26T08:53:13.479576Z",
     "shell.execute_reply.started": "2023-05-26T08:53:13.427826Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Conv2dBlock(torch.nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_c, out_c, kernel_size=3, padding='same')\n",
    "        self.bn1 = torch.nn.BatchNorm2d(out_c)\n",
    "        self.conv2 = torch.nn.Conv2d(out_c, out_c, kernel_size=3, padding='same')\n",
    "        self.bn2 = torch.nn.BatchNorm2d(out_c)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Conv2dTransposeBlock(torch.nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.ConvTranspose2d(in_channels=in_c, out_channels=out_c, kernel_size=(3,3))\n",
    "        self.bn1 = torch.nn.BatchNorm2d(out_c)\n",
    "        self.conv2 = torch.nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(out_c)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "#conv = torch.nn.Conv2d(in_channels= 3, out_channels= 16, kernel_size=(3,3), padding='same')\n",
    "\n",
    "class UNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        channels = [3, 16, 32, 64, 128, 256]\n",
    "\n",
    "        # Conolution layers where conv2d_1 = First Layer\n",
    "        self.conv2d_1 = Conv2dBlock(in_c=channels[0],out_c=channels[1])\n",
    "        self.conv2d_2 = Conv2dBlock(in_c=channels[1],out_c=channels[2])\n",
    "        self.conv2d_3 = Conv2dBlock(in_c=channels[2],out_c=channels[3])\n",
    "        self.conv2d_4 = Conv2dBlock(in_c=channels[3],out_c=channels[4])\n",
    "        self.conv2d_5 = Conv2dBlock(in_c=channels[4],out_c=channels[5])\n",
    "\n",
    "        # Decoding layers for upsampling where conv2dTranspose_1 = First Layer\n",
    "        self.conv2dTranspose_1 = torch.nn.ConvTranspose2d(in_channels=channels[5], out_channels=channels[4], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2d_6 = Conv2dBlock(in_c=channels[5], out_c=channels[4])\n",
    "        self.conv2dTranspose_2 = torch.nn.ConvTranspose2d(in_channels=channels[4], out_channels=channels[3], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2d_7 = Conv2dBlock(in_c=channels[4], out_c=channels[3])\n",
    "        self.conv2dTranspose_3 = torch.nn.ConvTranspose2d(in_channels=channels[3], out_channels=channels[2], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2d_8 = Conv2dBlock(in_c=channels[3], out_c=channels[2])\n",
    "        self.conv2dTranspose_4 = torch.nn.ConvTranspose2d(in_channels=channels[2], out_channels=channels[1], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2d_9 = Conv2dBlock(in_c=channels[2], out_c=channels[1])\n",
    "\n",
    "        # Define max pooling and dropout functions\n",
    "        self.maxPool = torch.nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.dropout = torch.nn.Dropout(p=0.1, inplace=False)\n",
    "        \n",
    "        # Classify prediction mask to single channel\n",
    "        self.segment = torch.nn.Conv2d(channels[1], 1, kernel_size=1, padding=0)\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding block\n",
    "        enc = []\n",
    "        for conv in [self.conv2d_1, self.conv2d_2, self.conv2d_3, self.conv2d_4]:\n",
    "            x = conv(x)\n",
    "            enc.append(x)\n",
    "            x = self.maxPool(x)\n",
    "            #x = self.dropout(x)\n",
    "        x = self.conv2d_5(x)\n",
    "\n",
    "        # Decoding block\n",
    "        for i, l in enumerate([[self.conv2dTranspose_1, self.conv2d_6], [self.conv2dTranspose_2, self.conv2d_7], \n",
    "                                [self.conv2dTranspose_3,self.conv2d_8], [self.conv2dTranspose_4, self.conv2d_9]]):\n",
    "            trans, conv = l[0], l[1]\n",
    "            x = trans(x, output_size=((x.size()[2])*(2), x.size()[3]*(2)))\n",
    "            x = torch.cat((x, enc[3-i]), axis=1)\n",
    "            #x = self.dropout(x)\n",
    "            x = conv(x)\n",
    "        \n",
    "        x = self.segment(x)\n",
    "        x = torch.squeeze(x)\n",
    "        #x = self.activation(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet2(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(UNet2, self).__init__()\n",
    "        channels = [3, 16, 32, 64, 128, 256]\n",
    "\n",
    "        # Conolution layers where conv2d_1 = First Layer\n",
    "        self.conv2d_1 = Conv2dBlock(in_c=channels[0],out_c=channels[1])\n",
    "        self.conv2d_2 = Conv2dBlock(in_c=channels[1],out_c=channels[2])\n",
    "        self.conv2d_3 = Conv2dBlock(in_c=channels[2],out_c=channels[3])\n",
    "        self.conv2d_4 = Conv2dBlock(in_c=channels[3],out_c=channels[4])\n",
    "        self.conv2d_5 = Conv2dBlock(in_c=channels[4],out_c=channels[5])\n",
    "\n",
    "        # Decoding layers for upsampling where conv2dTranspose_1 = First Layer\n",
    "        self.conv2dTranspose_1 = torch.nn.ConvTranspose2d(in_channels=channels[5], out_channels=channels[4], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2d_6 = Conv2dBlock(in_c=channels[5], out_c=channels[4])\n",
    "        self.conv2dTranspose_2 = torch.nn.ConvTranspose2d(in_channels=channels[4], out_channels=channels[3], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2d_7 = Conv2dBlock(in_c=channels[4], out_c=channels[3])\n",
    "        self.conv2dTranspose_3 = torch.nn.ConvTranspose2d(in_channels=channels[3], out_channels=channels[2], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2d_8 = Conv2dBlock(in_c=channels[3], out_c=channels[2])\n",
    "        self.conv2dTranspose_4 = torch.nn.ConvTranspose2d(in_channels=channels[2], out_channels=channels[1], kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2d_9 = Conv2dBlock(in_c=channels[2], out_c=channels[1])\n",
    "\n",
    "        # Define max pooling and dropout functions\n",
    "        self.maxPool = torch.nn.MaxPool2d(kernel_size=(2,2), stride=(2,2))\n",
    "        self.dropout = torch.nn.Dropout(p=0.1, inplace=False)\n",
    "        \n",
    "        # Classify prediction mask to single channel\n",
    "        self.segment = torch.nn.Conv2d(channels[1], 1, kernel_size=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding block\n",
    "        enc = []\n",
    "        for conv in [self.conv2d_1, self.conv2d_2, self.conv2d_3]:\n",
    "            x = conv(x)\n",
    "            enc.append(x)\n",
    "            x = self.maxPool(x)\n",
    "            x = self.dropout(x)\n",
    "        x = self.conv2d_4(x)\n",
    "\n",
    "        # Decoding block\n",
    "        for i, l in enumerate([[self.conv2dTranspose_2, self.conv2d_7], \n",
    "                                [self.conv2dTranspose_3,self.conv2d_8], [self.conv2dTranspose_4, self.conv2d_9]]):\n",
    "            trans, conv = l[0], l[1]\n",
    "            x = trans(x, output_size=((x.size()[2])*(2), x.size()[3]*(2)))\n",
    "            x = torch.cat((x, enc[2-i]), axis=1)\n",
    "            x = self.dropout(x)\n",
    "            x = conv(x)\n",
    "        \n",
    "        x = self.segment(x)\n",
    "        x = torch.squeeze(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def DeepLabModel():\n",
    "    model = torchvision.models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "    model.classifier[4] = torch.nn.Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1)) # Change final layer to 1 class.\n",
    "    return model\n",
    "\n",
    "def DeepLabV3_MobileNet_V3_Large():\n",
    "    model = torchvision.models.segmentation.deeplabv3_mobilenet_v3_large(weights=None, num_classes=1)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e98bc1f-9e98-4677-a091-20db7b354bd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T09:02:46.045856Z",
     "iopub.status.busy": "2023-05-26T09:02:46.045163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files from directories.\n",
      "Complete.\n",
      "Loading datasets...\n",
      "Complete.\n",
      "Dataloader Initiated.\n",
      "Running model on device cuda\n",
      "Initial learning rate set to  0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:23<00:00,  1.19it/s]\n",
      "100%|██████████| 25/25 [00:09<00:00,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "Epoch 0, Train Loss 0.930501, Train IOU 0.067282, Val Loss 0.914670, Val IOU 0.212370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:24<00:00,  1.19it/s]\n",
      "100%|██████████| 25/25 [00:08<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "Epoch 1, Train Loss 0.845671, Train IOU 0.217307, Val Loss 0.815703, Val IOU 0.374449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:24<00:00,  1.18it/s]\n",
      "100%|██████████| 25/25 [00:07<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "Epoch 2, Train Loss 0.590763, Train IOU 0.435956, Val Loss 0.626388, Val IOU 0.441104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:25<00:00,  1.17it/s]\n",
      "100%|██████████| 25/25 [00:10<00:00,  2.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "Epoch 3, Train Loss 0.411043, Train IOU 0.511926, Val Loss 0.537486, Val IOU 0.466399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:22<00:00,  1.21it/s]\n",
      "100%|██████████| 25/25 [00:10<00:00,  2.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "Epoch 4, Train Loss 0.351857, Train IOU 0.541262, Val Loss 0.476018, Val IOU 0.503255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:25<00:00,  1.17it/s]\n",
      "100%|██████████| 25/25 [00:10<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Train Loss 0.320999, Train IOU 0.563143, Val Loss 0.448714, Val IOU 0.497544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:28<00:00,  1.14it/s]\n",
      "100%|██████████| 25/25 [00:09<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model!\n",
      "Epoch 6, Train Loss 0.300410, Train IOU 0.578526, Val Loss 0.404608, Val IOU 0.533699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:03<01:22,  1.17it/s]"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "#import IProgress\n",
    "from datetime import datetime\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor, Resize\n",
    "import torch.nn.functional as F\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "def Configurations():\n",
    "    \"\"\" \n",
    "    Set the batch size for the data loader, large batch sizes can run into problems with memory.\n",
    "    Suggested batch sizes: 2, 4, 8, 16\n",
    "    \"\"\"\n",
    "    batch_size = 16\n",
    "\n",
    "    \"\"\"\n",
    "    Set the maximum number of epochs for the training phase, default setting of 1000. Model is likely\n",
    "    to converge before 1000 epochs when early stopping is set.\n",
    "    \"\"\"\n",
    "    max_epochs = 1000\n",
    "\n",
    "    \"\"\"\n",
    "    Set the patience for early stopping, defualt 15. The training phase will end once the validation IOU\n",
    "    has not increased for the number of epochs set in early stopping.\n",
    "    \"\"\"\n",
    "    early_stopping = 15\n",
    "\n",
    "    \"\"\"\n",
    "    Set the model architecture for deep learning.\n",
    "    Options: \n",
    "    'DeepLabModel()'\n",
    "    'UNet()'\n",
    "    'DeepLabV3_MobileNet_V3_Large()'\n",
    "    \"\"\"\n",
    "    #model = UNet()\n",
    "    model = DeepLabV3_MobileNet_V3_Large()\n",
    "    \n",
    "    DeepLab = True\n",
    "\n",
    "    \"\"\"\n",
    "    Set the model optimizer for training the selected model.\n",
    "    Options:\n",
    "    'SGD(model)'\n",
    "    'Adam(model)'\n",
    "    \"\"\"\n",
    "    if batch_size == 2:\n",
    "        optimizer = Adam(model, lr=0.0001)\n",
    "    elif batch_size == 16:\n",
    "        optimizer = SGD(model, lr=0.01)\n",
    "    else:\n",
    "        optimizer = Adam(model, lr=0.0001)\n",
    "\n",
    "    \"\"\"\n",
    "    Set the learning rate scheduler for the optimization function. The default selection is\n",
    "    'ReduceLROnPlateau' which decreases the learning rate by a factor of 10 when val IOU has not\n",
    "    increased for a patience of 5 epochs\n",
    "    \"\"\"\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5,\n",
    "    #                                                       patience=5, cooldown=5, min_lr=1e-6)\n",
    "    scheduler = None\n",
    "\n",
    "    \"\"\"\n",
    "    Set the loss function for training the model, default Dice.\n",
    "    Options:\n",
    "    'DiceLoss()'\n",
    "    'BCEWithLogitsLoss()'\n",
    "    \"\"\"\n",
    "    loss_fn = DiceLoss()\n",
    "\n",
    "    return batch_size, max_epochs, early_stopping, model, optimizer, scheduler, loss_fn, DeepLab\n",
    "\n",
    "def ReadDirectories():\n",
    "    print(\"Reading files from directories.\")\n",
    "    data_path = \"/notebooks/dfuSegmentation\"\n",
    "    # Set training directory\n",
    "    train_dir = os.path.join(data_path, \"dfuc2022/train/images\")\n",
    "    train_mask_dir = os.path.join(data_path, \"dfuc2022//train/masks\")\n",
    "\n",
    "    # Set validation directory\n",
    "    val_dir = os.path.join(data_path, \"dfuc2022/val/images\")\n",
    "    val_mask_dir = os.path.join(data_path, \"dfuc2022/val/masks\")\n",
    "\n",
    "    # Set test directory\n",
    "    test_dir = os.path.join(data_path, \"dfuc2022/test/\")\n",
    "\n",
    "    train_files = ReadFiles(train_dir)\n",
    "    train_masks = ReadFiles(train_mask_dir)\n",
    "\n",
    "    val_files = ReadFiles(val_dir)\n",
    "    val_masks = ReadFiles(val_mask_dir)\n",
    "\n",
    "    test_files = ReadFiles(test_dir)\n",
    "    print(\"Complete.\")\n",
    "\n",
    "    return train_files, train_masks, val_files, val_masks, test_files\n",
    "\n",
    "def Transforms():\n",
    "    transform_train = A.Compose([\n",
    "        #A.augmentations.dropout.cutout.Cutout(num_holes=8, max_h_size=8, max_w_size=8, fill_value=0, always_apply=False, p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        #A.RandomBrightnessContrast(p=0.2),\n",
    "        #A.augmentations.transforms.GaussNoise(var_limit=(100.0, 5000.0), mean=0, per_channel=True, always_apply=False, p=0.5),\n",
    "        A.augmentations.geometric.transforms.ShiftScaleRotate(\n",
    "            shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, interpolation=1, p=0.5),\n",
    "        A.augmentations.geometric.rotate.Rotate(limit=90, p=0.5),\n",
    "        A.augmentations.crops.transforms.CropAndPad(percent=(-0.3, 0.05), keep_size=True, p=0.5),\n",
    "        #A.augmentations.dropout.coarse_dropout.CoarseDropout(max_holes=50, max_height=8, max_width=8, p=0.5),\n",
    "        #A.augmentations.geometric.transforms.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, interpolation=1, border_mode=4, p=0.5),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    transform_test = A.Compose([\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    return transform_train, transform_test\n",
    "\n",
    "def main():\n",
    "    # Read directories into file lists.\n",
    "    train_files, train_masks, val_files, val_masks, test_files = ReadDirectories()\n",
    "    train_files, train_masks = train_files[0:1200], train_masks[0:1200]\n",
    "    test_files, test_masks = train_files[1200:], train_masks[1200:]\n",
    "\n",
    "    # Get transformations from Transforms()\n",
    "    transform_train, transform_test = Transforms()\n",
    "    \n",
    "    # Generate manual seed for reproducability\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    # Load dataset\n",
    "    print(\"Loading datasets...\")\n",
    "    train_ds = DFUDataset(train_files, train_masks, transform=transform_train)\n",
    "    val_ds = DFUDataset(val_files, val_masks, transform=transform_test)\n",
    "    print(\"Complete.\")\n",
    "\n",
    "    # Initiate DataLoader\n",
    "    batch_size, max_epochs, early_stopping, model, optimizer, scheduler, loss_fn, DeepLab = Configurations()\n",
    "    train_iter = DataLoader(train_ds, batch_size, shuffle=True, pin_memory=True)\n",
    "    val_iter = DataLoader(val_ds, batch_size, shuffle=True, pin_memory=True)\n",
    "    print(\"Dataloader Initiated.\")\n",
    "\n",
    "    # Set device for running model\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = 'mps'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    print(\"Running model on device {}\".format(device))\n",
    "\n",
    "    # Initiate segmentation model for training\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Model Training\n",
    "    Train(model, max_epochs, optimizer, scheduler, loss_fn, train_iter, val_iter, device, early_stopping, DeepLab)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e5e713-6885-4f3f-bffd-3c6cbceb69ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
